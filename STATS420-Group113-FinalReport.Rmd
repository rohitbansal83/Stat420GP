---
title: "STAT420-Group113 : Analysis of New York `Energy-Star` rating using linear regression"
author: "Rohit Bansal (rbansal3), Manas Kumar Mukherjee (manaskm2)"
date: "8/02/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Introduction
<!-- What is this data? Where did it come from? What are the variables? Why is it interesting to you? -->
<!-- Why are you creating a model for this data? What is the goal of this model? -->

#### Motivation

In today's world, global warming and pollution are two biggest threats for human existence. We wanted to apply our newly learned linear-regression skills to get meaningful insights using some real data related to these issues. 

As part of our research, we found that there were some significant work done by the Mayor's office of the New York city in order to improve the energy efficiency of buildings. 

As per [NYC Sustainability site](https://www1.nyc.gov/site/sustainability/our-programs/buildings.page) "In most major cities in the US, transportation produces the bulk of emissions. In New York City, 68% of emissions come from buildings. Almost half of those emissions come from only 2% of buildings. To counter this, the city needs aggressive retrofits to make existing buildings more efficient."

##### Objective 

The objective is to use the energy data to build a model that can predict the Energy Star Score of a building and interpret the results to find the factors which influence the score. 

#### Description of the dataset

The original dataset is taken from the Govt. of New York's website. 

- Website - https://www1.nyc.gov/site/sustainability/our-programs/buildings.page
- File ref - https://www1.nyc.gov/html/gbee/downloads/misc/nyc_benchmarking_disclosure_data_reported_in_2017.xlsb

This dataset represents the Public Disclosure of benchmarking data for energy consumed in 2016. It contains data for lots with a single building and campuses.

The data defination of the individual columns are mentioned in the following file. 
http://www.nyc.gov/html/gbee/downloads/misc/nyc_benchmarking_disclosure_data_definitions_2017.pdf

In this dataset, we'll be using the `ENERGY STAR Score` as the response variable. We're interested in building an accurate and interpretable linear regression model and in identifying significant `ENERGY STAR Score` predictors.
There are `53` other columns in this dataset. From a very high-level overview, we think a few of the following columns might be useful predictors: `Year Built`, `Occupancy`, `Natural Gas Use (kBtu)`, `Water Required?` etc.


## Methods
<!-- This section should contain any information about data preparation that is performed to the original data before modelling. -->
<!-- Multiple linear regression -->
<!-- Dummy variables  -->
<!-- Interaction -->
<!-- Residual diagnostics -->
<!-- Outlier diagnostics -->
<!-- Transformations -->
<!-- Polynomial regression -->
<!-- Model selection -->

#### - Step1: Data preparation
1a. High level data. Mention dimension 

As the first step we will load the data and rename the variable names in order to remove the space in the variable name. Also, Since `ENERGY.STAR.Score` is the response variable, we removing the records where the `ENERGY.STAR.Score` is not available. 

```{r}
nyc_data_original = read.csv('NYC-BuildingEnergyData-FromSite_original.csv')
names(nyc_data_original) = make.names(names(nyc_data_original), unique=TRUE)
nyc_data_original = subset(nyc_data_original, nyc_data_original$ENERGY.STAR.Score != "Not Available")
dim(nyc_data_original)
```

So the original data set has 9,642 observations and 54 variables. 

- After observing the data, we found that the following variables are for informational and tracking purpose and does not have any relevance for our analysis. So we deleted these variables from our dataset. 

Order
Property.Id
Property.Name
Parent.Property.Id
Parent.Property.Name
BBL...10.digits
NYC.Borough..Block.and.Lot..BBL..self.reported
NYC.Building.Identification.Number..BIN.
Address.1..self.reported.
Address.2
Postal.Code
Street.Number
Street.Name
Release.Date
DOF.Benchmarking.Submission.Status
List.of.All.Property.Use.Types.at.Property
Metered.Areas..Energy.

```{r}
#First we have to rename the column names to remove the space in the column name


nyc_data_clean = subset(nyc_data_original, select = -c(Order, Property.Id, Property.Name, Parent.Property.Id,
                                                      Parent.Property.Name, BBL...10.digits, NYC.Borough..Block.and.Lot..BBL..self.reported,                                                                       NYC.Building.Identification.Number..BIN.,Address.1..self.reported., Address.2,                                                                               Postal.Code,Street.Number,Street.Name, Release.Date, DOF.Benchmarking.Submission.Status,
                                                      List.of.All.Property.Use.Types.at.Property, Metered.Areas..Energy.))
dim(nyc_data_clean)
```
After removing the unwanted variables, we have 39 variables. 

- After this we checked for null/not avialable data for variables. 

```{r}
library(knitr)
number_of_columns = ncol(nyc_data_clean)

not_available_values = rep(0, number_of_columns)

ind = 1
for (col in names(nyc_data_clean)){
  not_available_values[ind] = round(mean(nyc_data_clean[,col]=="Not Available"),2)
  ind = ind + 1
}

data_frame = data.frame(column_names = names(nyc_data_clean), num_of_not_available = not_available_values)
dt = data_frame[order(-data_frame$num_of_not_available),]
kable(x = dt)
```


Based on the above table we found that following variables have missing data for more than more than 75% of observations.Also based on our domain knowledge these variables looks insignificant for our analysis. Thus we will not be considering these variables as well

- Fuel.Oil..1.Use..kBtu.
- Diesel..2.Use..kBtu.	
- Fuel.Oil..5…6.Use..kBtu.	
- X3rd.Largest.Property.Use.Type	
- X3rd.Largest.Property.Use.Type…Gross.Floor.Area..ft..	
- District.Steam.Use..kBtu.	
- Fuel.Oil..4.Use..kBtu.	
- Fuel.Oil..2.Use..kBtu.	
- X2nd.Largest.Property.Use.Type	
- X2nd.Largest.Property.Use…Gross.Floor.Area..ft..	



```{r}
nyc_data_clean = subset(nyc_data_clean, select = -c(Fuel.Oil..1.Use..kBtu.,Diesel..2.Use..kBtu.,Fuel.Oil..5...6.Use..kBtu.,X3rd.Largest.Property.Use.Type,
                                                       X3rd.Largest.Property.Use.Type...Gross.Floor.Area..ft..,District.Steam.Use..kBtu.,
                                                       Fuel.Oil..4.Use..kBtu.,Fuel.Oil..2.Use..kBtu.,X2nd.Largest.Property.Use.Type,
                                                       X2nd.Largest.Property.Use...Gross.Floor.Area..ft..))
dim(nyc_data_clean)




```

after deleting the unwanted variables we have 29 variables. Lets have a looks at the varialbes and the missing data status.


```{r}

number_of_columns = ncol(nyc_data_clean)

not_available_values = rep(0, number_of_columns)

ind = 1
for (col in names(nyc_data_clean)){
  not_available_values[ind] = round(mean(nyc_data_clean[,col]=="Not Available"),2)
  ind = ind + 1
}

data_frame = data.frame(column_names = names(nyc_data_clean), num_of_not_available = not_available_values)
dt = data_frame[order(-data_frame$num_of_not_available),]
kable(x = dt)



```

While loading the csv, quite a few variables were converted to factor variables as the data was numeric but contained "Not Available" for some records. Converting those recods back to the numeric variable

```{r}

nyc_data_clean$Water.Intensity..All.Water.Sources...gal.ft.. = as.numeric(as.character(nyc_data_clean$Water.Intensity..All.Water.Sources...gal.ft..))
nyc_data_clean$Source.EUI..kBtu.ft.. = as.numeric(as.character(nyc_data_clean$Source.EUI..kBtu.ft..))
nyc_data_clean$Water.Use..All.Water.Sources...kgal. = as.numeric(as.character(nyc_data_clean$Water.Use..All.Water.Sources...kgal.))
nyc_data_clean$Largest.Property.Use.Type...Gross.Floor.Area..ft.. = as.numeric(as.character(nyc_data_clean$Largest.Property.Use.Type...Gross.Floor.Area..ft..))

nyc_data_clean$Site.EUI..kBtu.ft.. = as.numeric(as.character(nyc_data_clean$Site.EUI..kBtu.ft..))

nyc_data_clean$Weather.Normalized.Site.EUI..kBtu.ft.. = as.numeric(as.character(nyc_data_clean$Weather.Normalized.Site.EUI..kBtu.ft..))

nyc_data_clean$Weather.Normalized.Site.Electricity.Intensity..kWh.ft.. = as.numeric(as.character(nyc_data_clean$Weather.Normalized.Site.Electricity.Intensity..kWh.ft..))

nyc_data_clean$Weather.Normalized.Site.Natural.Gas.Intensity..therms.ft.. = as.numeric(as.character(nyc_data_clean$Weather.Normalized.Site.Natural.Gas.Intensity..therms.ft..))

nyc_data_clean$Weather.Normalized.Source.EUI..kBtu.ft.. = as.numeric(as.character(nyc_data_clean$Weather.Normalized.Source.EUI..kBtu.ft..))

nyc_data_clean$Natural.Gas.Use..kBtu. = as.numeric(as.character(nyc_data_clean$Natural.Gas.Use..kBtu.))

nyc_data_clean$Weather.Normalized.Site.Natural.Gas.Use..therms. = as.numeric(as.character(nyc_data_clean$Weather.Normalized.Site.Natural.Gas.Use..therms.))

nyc_data_clean$Electricity.Use...Grid.Purchase..kBtu. = as.numeric(as.character(nyc_data_clean$Electricity.Use...Grid.Purchase..kBtu.))

nyc_data_clean$Weather.Normalized.Site.Electricity..kWh. = as.numeric(as.character(nyc_data_clean$Weather.Normalized.Site.Electricity..kWh.))

nyc_data_clean$Total.GHG.Emissions..Metric.Tons.CO2e. = as.numeric(as.character(nyc_data_clean$Total.GHG.Emissions..Metric.Tons.CO2e.))

nyc_data_clean$Direct.GHG.Emissions..Metric.Tons.CO2e. = as.numeric(as.character(nyc_data_clean$Direct.GHG.Emissions..Metric.Tons.CO2e.))

nyc_data_clean$Indirect.GHG.Emissions..Metric.Tons.CO2e. = as.numeric(as.character(nyc_data_clean$Indirect.GHG.Emissions..Metric.Tons.CO2e.))

nyc_data_clean[ nyc_data_clean$Water.Required. == "",]['Water.Required.'] = 'Yes'

building_data = ifelse(nyc_data_clean$Metered.Areas...Water. == "Whole Building", 'WholeBuilding', "Other")
nyc_data_clean$Metered.Areas...Water. = as.factor(building_data)

#Lets change the response variable name and convert it into a numeric variable:
names(nyc_data_clean)[names(nyc_data_clean) =='ENERGY.STAR.Score'] = 'Score'
nyc_data_clean$Score = as.numeric(nyc_data_clean$Score)

str(nyc_data_clean)
```



So without removing any observation we have cleaned our dataset to a good extent. Now lets do some more analysis on our data. This data is for all the building in New York City and their energy rating. The different type of buildings will have different energy consumption pattern and thus the model should be differnet for them. So lets analyze the range of values we have for the property type.

```{r}
sort(table(nyc_data_clean$Largest.Property.Use.Type),decreasing = TRUE)

```

So more than 75% of the data is for "Multifamily Housing". Next biggest category is "Office" with more than 10% of the record. Rest all the categories makes roughly around 10% of the data combined. So we will be categorizing the property types in 3 broad categories:
---MultiFamilyHousing
---Office
---Others

We will add a dummy variable to do so.

```{r}
nyc_data_clean$building_type = ifelse(nyc_data_clean$Largest.Property.Use.Type == "Multifamily Housing", 'MultiFamilyHousing',
                                      ifelse(nyc_data_clean$Largest.Property.Use.Type =="Office", "Office", "Others"))

nyc_data_clean$building_type = as.factor(nyc_data_clean$building_type)
table(nyc_data_clean$building_type)

str(nyc_data_clean)
```




```{r}

par(mfrow = c(1,3))
x = nyc_data_clean[nyc_data_clean$building_type=="MultiFamilyHousing",]
y = nyc_data_clean[nyc_data_clean$building_type=="Office",]
z = nyc_data_clean[nyc_data_clean$building_type=="Others",]

hist(x$Score, col    = "dodgerblue")
hist(y$Score, col    = "dodgerblue")
hist(z$Score, col    = "dodgerblue")
```


1b. Remove unnessary variables based the data (null removal, imputation, row removal)

```{r}
names(nyc_data_clean)
write.csv(nyc_data_clean, "nyc_data_clean.csv") 

```

<!-- 	column_names	num_of_not_available -->
<!-- 10	Metered.Areas…Water.	0.39 -->
<!-- 25	Water.Use..All.Water.Sources…kgal.	0.32 -->
<!-- 26	Water.Intensity..All.Water.Sources…gal.ft..	0.32 -->
<!-- 15	Weather.Normalized.Site.Natural.Gas.Intensity..therms.ft..	0.15 -->
<!-- 18	Weather.Normalized.Site.Natural.Gas.Use..therms.	0.15 -->
<!-- 13	Weather.Normalized.Site.EUI..kBtu.ft..	0.11 -->
<!-- 16	Weather.Normalized.Source.EUI..kBtu.ft..	0.11 -->
<!-- 17	Natural.Gas.Use..kBtu.	0.10 -->
<!-- 14	Weather.Normalized.Site.Electricity.Intensity..kWh.ft..	0.05 -->



```{r}
#change factor to numeric(min-max scaler)
#3 TBD : log
#par(mfrow = c(1,2))
#hist(nyc_data_clean$Source.EUI..kBtu.ft..)
#hist(log(nyc_data_clean$Source.EUI..kBtu.ft..))

nyc_data_clean$Source.EUI..kBtu.ft.. = log(nyc_data_clean$Source.EUI..kBtu.ft..)
```


```{r}
#TODO
# DOF.Gross.Floor.Area : 63
#nrow(nyc_data_clean[which(nyc_data_clean$DOF.Gross.Floor.Area == "NA"), ])
#nyc_data_clean$DOF.Gross.Floor.Area[1:10]

nyc_data_clean$DOF.Gross.Floor.Area =   ifelse(is.na(nyc_data_clean$DOF.Gross.Floor.Area), 0, as.numeric(nyc_data_clean$DOF.Gross.Floor.Area))[1:10]

```

```{r}
nrow(nyc_data_clean[which(nyc_data_clean$Year.Built == 0), ])
range01 = function(x){(x-min(x))/(max(x)-min(x))}

# min-max scaler
#par(mfrow=c(1,2))
#hist(nyc_data_clean$Year.Built)
#hist(range01(nyc_data_clean$Year.Built))
```


```{r}
# Number.of.Buildings...Self.reported
#hist(nyc_data_clean$Number.of.Buildings...Self.reported)
#hist(log(nyc_data_clean$Number.of.Buildings...Self.reported))

range01 = function(x){(x-min(x))/(max(x)-min(x))}   

scaled_value = range01(nyc_data_clean$Number.of.Buildings...Self.reported)
nyc_data_clean$Number.of.Buildings...Self.reported = scaled_value
```


```{r}
#Occupancy
hist(nyc_data_clean$Occupancy)
scaled_value = range01(nyc_data_clean$Occupancy)
nyc_data_clean$Occupancy = scaled_value
```

```{r}
hist(nyc_data_clean$Property.GFA...Self.Reported..ft..)
scaled_value = range01(nyc_data_clean$Property.GFA...Self.Reported..ft..)
nyc_data_clean$Property.GFA...Self.Reported..ft.. = scaled_value
```

1c. EDA ( Data exploration ). Plot pair plot between the target and other predictor variables.
1d. Final data for different models (2/3 csv files)

Step2: Find full additive model. 
2a. Create a benchmark prediction

Step3: Find an optimal model 
3a. use `Step` function
3b. Apply transformation 
3c. Check model assumptions 
3d. Check colinearity 
3d. Check outliers and/or influential points. 

## Results
<!-- The results section should contain numerical or graphical summaries of your results. You should report a final model you have chosen. There is not necessarily one, singular correct model, but certainly some methods and models are better than others in certain situations. You may use any methods we studied this semester to complete this task, and provide evidence that your final choice of model is a good one. -->

Train-Test split ( using CV ). Predict
Explain the model using R-Squared, significance of predictor variables. 

## Discussion
The discussion section should contain discussion of your results and should frame your results in the context of the data. How is your final model useful?

Why multiple models ? Comparative analysis between models 
R2 improvement between baseline and optimized models. 

## Appendix
The appendix section should contain code and analysis that is used, but that may clutter the report or is not directly related to the choice of model.

There are standard models used by Govt.
We can compare our model with those standard models. 

<!-- Use of Statistical Methodology: 30 -->
<!-- Have you used the appropriate methods for your dataset? Have you applied them correctly? -->
<!-- Use of R: 15 -->
<!-- Does your code perform the desired task? Is your code readable? -->
<!-- Interpretation of Results: 15 -->
<!-- Do you arrive at the correct statistical conclusions from the analyses you perform? -->
<!-- Discussion of Results: 15 -->
<!-- Do you discuss your analysis results in the context of the data? -->
<!-- Organization and Neatness: 25 -->
<!-- Is your report easy to read? Does it use RMarkdown well? Is it written in a manner such that a reader does not already need to be familiar with the data? -->
