---
title: "STAT420-Group113 : Analysis of New York `Energy-Star` rating using linear regression"
author: "Rohit Bansal (rbansal3), Manas Kumar Mukherjee (manaskm2)"
date: "8/02/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Introduction
<!-- What is this data? Where did it come from? What are the variables? Why is it interesting to you? -->
<!-- Why are you creating a model for this data? What is the goal of this model? -->

#### Motivation

In today's world, global warming and pollution are two biggest threats for human existence. We wanted to apply our newly learned linear-regression skills to get meaningful insights using some real data related to these issues. 

As part of our research, we found that there were some significant work done by the Mayor's office of the New York city in order to improve the energy efficiency of buildings. 

As per [NYC Sustainability site](https://www1.nyc.gov/site/sustainability/our-programs/buildings.page) "In most major cities in the US, transportation produces the bulk of emissions. In New York City, 68% of emissions come from buildings. Almost half of those emissions come from only 2% of buildings. To counter this, the city needs aggressive retrofits to make existing buildings more efficient."

##### Objective 

The objective is to use the energy data to build a model that can predict the Energy Star Score of a building and interpret the results to find the factors which influence the score. 

#### Description of the dataset

The original dataset is taken from the Govt. of New York's website. 

- Website - https://www1.nyc.gov/site/sustainability/our-programs/buildings.page
- File ref - https://www1.nyc.gov/html/gbee/downloads/misc/nyc_benchmarking_disclosure_data_reported_in_2017.xlsb

This dataset represents the Public Disclosure of benchmarking data for energy consumed in 2016. It contains data for lots with a single building and campuses.

The data defination of the individual columns are mentioned in the following file. 
http://www.nyc.gov/html/gbee/downloads/misc/nyc_benchmarking_disclosure_data_definitions_2017.pdf

In this dataset, we'll be using the `ENERGY STAR Score` as the response variable. We're interested in building an accurate and interpretable linear regression model and in identifying significant `ENERGY STAR Score` predictors.
There are `53` other columns in this dataset. From a very high-level overview, we think a few of the following columns might be useful predictors: `Year Built`, `Occupancy`, `Natural Gas Use (kBtu)`, `Water Required?` etc.


## Methods
<!-- This section should contain any information about data preparation that is performed to the original data before modelling. -->
<!-- Multiple linear regression -->
<!-- Dummy variables  -->
<!-- Interaction -->
<!-- Residual diagnostics -->
<!-- Outlier diagnostics -->
<!-- Transformations -->
<!-- Polynomial regression -->
<!-- Model selection -->

#### - Step1: Data preparation
1a. High level data. Mention dimension 

Since `ENERGY.STAR.Score` is the response variable, we removing the records where the `ENERGY.STAR.Score` is not available. 

```{r}
nyc_data_original = read.csv('NYC-BuildingEnergyData-FromSite_original.csv')
nyc_data_original = subset(nyc_data_original, nyc_data_original$ENERGY.STAR.Score != "Not Available")
dim(nyc_data_original)
```

So the original data set has 9,642 records and 54 columns. 

- After observing the data, we found that the following columns are not relevant for our analysis. So we deleted this columns from our dataset. 

Order
Property Id
Property Name
Parent Property Id
Parent Property Name
BBL - 10 digits
NYC Borough, Block and Lot (BBL) self-reported
NYC Building Identification Number (BIN)
Address 1 (self-reported)
Address 2
Postal Code
Street Number
Street Name
Release Date
DOF Benchmarking Submission Status

```{r}

names(nyc_data_original) = make.names(names(nyc_data_original), unique=TRUE)
names(nyc_data_original)
nyc_data_clean = subset(nyc_data_original, select = -c(Order, Property.Id, Property.Name, Parent.Property.Id,
                                                            Parent.Property.Name, BBL...10.digits, NYC.Borough..Block.and.Lot..BBL..self.reported, NYC.Building.Identification.Number..BIN.,
                                                          Address.1..self.reported., Address.2, Postal.Code,Street.Number, 
                                                          Street.Name, Release.Date, DOF.Benchmarking.Submission.Status))
dim(nyc_data_clean)
```
After removing the unwanted columns, we have 39 columns or predictors. 

- Based on the significantly high number of null or 'Not Applicable' values, we have removed the following columns as well.

```{r}
library(knitr)
number_of_columns = ncol(nyc_data_clean)

not_available_values = rep(0, number_of_columns)

ind = 1
for (col in names(nyc_data_clean)){
  not_available_values[ind] = round(mean(nyc_data_clean[,col]=="Not Available"),2)
  ind = ind + 1
}

data_frame = data.frame(column_names = names(nyc_data_clean), num_of_not_available = not_available_values)
dt = data_frame[order(-data_frame$num_of_not_available),]
kable(x = dt)
```

The above table shows that for the following columns, more than 75% of the values are `Not Available`.
Because of this much huge missing data, these columns are not considered in the modeling. 
Based on our domain knowlegge, it is found that these columns don't have any significant data. 

- Fuel.Oil..1.Use..kBtu.
- Diesel..2.Use..kBtu.	
- Fuel.Oil..5…6.Use..kBtu.	
- 3rd.Largest.Property.Use.Type	
- X3rd.Largest.Property.Use.Type…Gross.Floor.Area..ft..	
- District.Steam.Use..kBtu.	
- Fuel.Oil..4.Use..kBtu.	
- Fuel.Oil..2.Use..kBtu.	
- X2nd.Largest.Property.Use.Type	
- X2nd.Largest.Property.Use…Gross.Floor.Area..ft..	

```{r}
nyc_data_clean = subset(nyc_data_clean, select = -c(data_frame$column_names[1:10]))
```





1b. Remove unnessary variables based the data (null removal, imputation, row removal)


1c. EDA ( Data exploration ). Plot pair plot between the target and other predictor variables.
1d. Final data for different models (2/3 csv files)

Step2: Find full additive model. 
2a. Create a benchmark prediction

Step3: Find an optimal model 
3a. use `Step` function
3b. Apply transformation 
3c. Check model assumptions 
3d. Check colinearity 
3d. Check outliers and/or influential points. 

## Results
<!-- The results section should contain numerical or graphical summaries of your results. You should report a final model you have chosen. There is not necessarily one, singular correct model, but certainly some methods and models are better than others in certain situations. You may use any methods we studied this semester to complete this task, and provide evidence that your final choice of model is a good one. -->

Train-Test split ( using CV ). Predict
Explain the model using R-Squared, significance of predictor variables. 

## Discussion
The discussion section should contain discussion of your results and should frame your results in the context of the data. How is your final model useful?

Why multiple models ? Comparative analysis between models 
R2 improvement between baseline and optimized models. 

## Appendix
The appendix section should contain code and analysis that is used, but that may clutter the report or is not directly related to the choice of model.

There are standard models used by Govt.
We can compare our model with those standard models. 

<!-- Use of Statistical Methodology: 30 -->
<!-- Have you used the appropriate methods for your dataset? Have you applied them correctly? -->
<!-- Use of R: 15 -->
<!-- Does your code perform the desired task? Is your code readable? -->
<!-- Interpretation of Results: 15 -->
<!-- Do you arrive at the correct statistical conclusions from the analyses you perform? -->
<!-- Discussion of Results: 15 -->
<!-- Do you discuss your analysis results in the context of the data? -->
<!-- Organization and Neatness: 25 -->
<!-- Is your report easy to read? Does it use RMarkdown well? Is it written in a manner such that a reader does not already need to be familiar with the data? -->
